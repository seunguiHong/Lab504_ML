{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- QUIET MODE (put these lines at very top) ----------\n",
    "import os, sys, types, warnings\n",
    "os.environ[\"TQDM_NOTEBOOK\"] = \"0\"  # tqdm.auto가 노트북 모드로 안 가게\n",
    "\n",
    "try:\n",
    "    import tqdm as _tqdm\n",
    "    _auto = types.ModuleType(\"tqdm.auto\"); _auto.tqdm = _tqdm.tqdm\n",
    "    sys.modules[\"tqdm.auto\"] = _auto\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "from sklearn.exceptions import DataConversionWarning, ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=DataConversionWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\".*IProgress not found.*\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\".*X does not have valid feature names.*\", category=UserWarning)\n",
    "# -------------------------------------------------------------\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from rolling_framework import ExpandingRunner, make_strategy\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "DATA_FILE     = os.path.join(\"\", \"dataset.csv\")     # index='Time'\n",
    "Y_COLS        = [\"xr_2\", \"xr_3\", \"xr_5\", \"xr_7\", \"xr_10\"]\n",
    "Y_10_COL      = \"xr_10\"\n",
    "\n",
    "SLOPE_PREFIX  = \"s_\"\n",
    "FWD_PREFIX    = \"fwd_\"\n",
    "MACRO_PREFIX  = \"F\"\n",
    "\n",
    "PERIOD        = [\"197108\", \"202312\"]\n",
    "BURN_IN_END   = \"200609\"\n",
    "HORIZON       = 12\n",
    "SHOW_PROGRESS = True\n",
    "\n",
    "# 반복 횟수 및 seed\n",
    "N_RUNS        = 20\n",
    "BASE_SEED     = 42\n",
    "\n",
    "# ---------------- Ridge 설정 (TS-CV) ----------------\n",
    "# base Ridge 파라미터(고정값). alpha는 CV grid에서 조정.\n",
    "RIDGE_PARAMS_BASE = dict(\n",
    "    random_state=None\n",
    ")\n",
    "\n",
    "RIDGE_CV = dict(\n",
    "    mode=\"tscv\",\n",
    "    n_splits=10,\n",
    "    grid={\n",
    "        \"alpha\": [1e-4, 1e-3, 1e-2, 1e-1, 1.0, 10.0],\n",
    "    },\n",
    ")\n",
    "\n",
    "# ---------------- MLP 설정 (hold-out CV) ----------------\n",
    "# Sklearn MLPRegressor용 base 파라미터(공통)\n",
    "MLP_PARAMS_BASE = dict(\n",
    "    max_iter=2000,\n",
    "    early_stopping=True,\n",
    "    learning_rate_init=1e-3,\n",
    "    tol=1e-5,\n",
    "    # hidden_layer_sizes, alpha는 CV grid로 튜닝\n",
    "    random_state=None,\n",
    ")\n",
    "\n",
    "# hold-out CV: 한 번의 train/validation split\n",
    "MLP_CV = dict(\n",
    "    mode=\"holdout\",\n",
    "    val_ratio=0.2,\n",
    "    grid={\n",
    "        # SDMlp 노트북에서 쓰던 구조에 맞춰, 비교적 작은 네트워크와 큰 L2\n",
    "        \"hidden_layer_sizes\": [(16,), (16, 8)],\n",
    "        \"alpha\": [1e3, 1e5, 1e7],\n",
    "    },\n",
    ")\n",
    "\n",
    "# ---------------- SDMLP base params ----------------\n",
    "# SDMLP 내부 구현에 맞춰 사용 (표준화는 외부에서 처리한다고 가정)\n",
    "SDMLP_PARAMS_BASE = dict(\n",
    "    hidden_layer_sizes=(16,),   # 필요시 수정\n",
    "    alpha=1e5,\n",
    "    max_iter=2000,\n",
    "    early_stopping=True,\n",
    "    learning_rate_init=1e-3,\n",
    "    tol=1e-5,\n",
    "    random_state=None,\n",
    "    # slope_lr 등 추가 파라미터가 있다면 SDMLP 전략 구현에 맞게 확장\n",
    ")\n",
    "\n",
    "# ---------------- mini utils ----------------\n",
    "def read_df(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, index_col=\"Time\")\n",
    "    df.index = df.index.astype(str)\n",
    "    return df\n",
    "\n",
    "def features(df: pd.DataFrame, *, use_fwd: bool, use_macro: bool) -> pd.DataFrame:\n",
    "    parts = []\n",
    "    if use_fwd:\n",
    "        parts.append(df.loc[:, df.columns.str.startswith(FWD_PREFIX)])\n",
    "    if use_macro:\n",
    "        parts.append(df.loc[:, df.columns.str.startswith(MACRO_PREFIX)])\n",
    "    if not parts:\n",
    "        raise ValueError(\"No features selected (fwd/macro).\")\n",
    "    return pd.concat(parts, axis=1)\n",
    "\n",
    "def cs_baseline(runner: ExpandingRunner, df: pd.DataFrame, y: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Per-maturity Campbell–Shiller OLS baseline:\n",
    "        xr_j ~ s_j\n",
    "\n",
    "    Returns:\n",
    "        DataFrame indexed by runner.test_times, columns=Y_COLS\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for t in runner.test_times:\n",
    "        tr = [s for s in runner.times if s < t]\n",
    "        if not tr:\n",
    "            continue\n",
    "        row = {}\n",
    "        for ycol in Y_COLS:\n",
    "            mat  = ycol.split(\"_\", 1)[1]\n",
    "            scol = f\"{SLOPE_PREFIX}{mat}\"\n",
    "            X_tr = df.loc[tr, [scol]].astype(float)\n",
    "            y_tr = y.loc[tr, ycol].astype(float).values\n",
    "            reg  = LinearRegression().fit(X_tr, y_tr)\n",
    "            x_te = df.loc[[t], [scol]].astype(float)\n",
    "            row[ycol] = float(reg.predict(x_te)[0])\n",
    "        rows.append(pd.Series(row, name=t))\n",
    "    return pd.DataFrame(rows).reindex(index=runner.test_times, columns=Y_COLS)\n",
    "\n",
    "def mse10_from_runner(runner: ExpandingRunner, y_col: str = Y_10_COL) -> pd.Series:\n",
    "    \"\"\"\n",
    "    xr_10에 대한 시점별 제곱오차 SE_t = (y_true - y_pred)^2 반환.\n",
    "    \"\"\"\n",
    "    Y_true, Y_pred = runner.collect_frames()\n",
    "    se_10 = (Y_pred[y_col] - Y_true[y_col]) ** 2\n",
    "    se_10.name = \"MSE_10\"\n",
    "    return se_10\n",
    "\n",
    "def save_mse10_mean(se_list, csv_path: str) -> None:\n",
    "    \"\"\"\n",
    "    여러 run의 SE_t 시리즈 리스트를 받아 run 방향으로 평균낸 MSE_10(t)를 CSV로 저장.\n",
    "    \"\"\"\n",
    "    df = pd.concat(se_list, axis=1)\n",
    "    mse_mean = df.mean(axis=1)\n",
    "    mse_mean.name = \"MSE_10\"\n",
    "    mse_mean.to_csv(csv_path, header=True)\n",
    "\n",
    "# ---------------- RUN EXPERIMENTS -------------------\n",
    "if __name__ == \"__main__\":\n",
    "    df = read_df(DATA_FILE)\n",
    "    y  = df[Y_COLS].copy()\n",
    "\n",
    "    # slope 컬럼 (CS / SDMLP용)\n",
    "    slope_cols = [f\"{SLOPE_PREFIX}{col.split('_', 1)[1]}\" for col in Y_COLS]\n",
    "    X_slope = df[slope_cols].copy()\n",
    "    slope_map = {ycol: f\"{SLOPE_PREFIX}{ycol.split('_', 1)[1]}\" for ycol in Y_COLS}\n",
    "\n",
    "    # feature set 정의\n",
    "    feature_sets = {\n",
    "        \"fwd\":       dict(use_fwd=True,  use_macro=False),\n",
    "        \"fwd_macro\": dict(use_fwd=True,  use_macro=True),\n",
    "    }\n",
    "\n",
    "    for tag, fspec in feature_sets.items():\n",
    "        print(f\"\\n================ Feature set: {tag} ================\")\n",
    "        X_feat = features(df, use_fwd=fspec[\"use_fwd\"], use_macro=fspec[\"use_macro\"])\n",
    "        feat_cols = list(X_feat.columns)\n",
    "\n",
    "        # SDMLP / CSARM용 X (slope + features)\n",
    "        X_cs = pd.concat([X_slope, X_feat], axis=1)\n",
    "\n",
    "        # 모델별 SE(t) accumulator\n",
    "        mse_runs_ridge      = []\n",
    "        mse_runs_csarm      = []\n",
    "        mse_runs_mlp        = []\n",
    "        mse_runs_sdmlp      = []\n",
    "\n",
    "        for run in range(N_RUNS):\n",
    "            seed = BASE_SEED + run\n",
    "            print(f\"\\n--- {tag} | run {run+1}/{N_RUNS} | seed={seed} ---\")\n",
    "\n",
    "            # ---------- 1) Ridge (TS-CV) ----------\n",
    "            ridge_params = dict(RIDGE_PARAMS_BASE)\n",
    "            ridge_params[\"random_state\"] = seed  # 비록 Ridge는 deterministic이지만 일관성 유지\n",
    "\n",
    "            ridge = make_strategy(\n",
    "                \"Ridge\",\n",
    "                target_cols=Y_COLS,\n",
    "                feature_cols=feat_cols,\n",
    "                params=ridge_params,\n",
    "                scale=True,\n",
    "                cv=RIDGE_CV,\n",
    "            )\n",
    "\n",
    "            runner_ridge = ExpandingRunner(\n",
    "                X=X_feat,\n",
    "                y=y,\n",
    "                strategy=ridge,\n",
    "                period=PERIOD,\n",
    "                burn_in_end=BURN_IN_END,\n",
    "                horizon=HORIZON,\n",
    "            )\n",
    "            runner_ridge.fit_walk(progress=SHOW_PROGRESS, desc=f\"Ridge [{tag}] (run={run+1})\")\n",
    "\n",
    "            se_ridge = mse10_from_runner(runner_ridge)\n",
    "            mse_runs_ridge.append(se_ridge)\n",
    "\n",
    "            # 첫 run에서만 CS baseline 및 R^2 출력, MAT 저장\n",
    "            if run == 0:\n",
    "                y_cs_hat = cs_baseline(runner_ridge, df, y)\n",
    "\n",
    "                print(f\"\\n=== Ridge [{tag}] (run=1) ===\")\n",
    "                print(\"R2OOS vs naive:\\n\",    runner_ridge.R2OOS(baseline=\"naive\").round(4))\n",
    "                print(\"R2OOS vs condmean:\\n\", runner_ridge.R2OOS(baseline=\"condmean\").round(4))\n",
    "                print(\"R2OOS vs CS OLS:\\n\",   runner_ridge.R2OOS(baseline=\"custom\", benchmark=y_cs_hat).round(4))\n",
    "\n",
    "                runner_ridge.to_mat(f\"ridge_{tag}.mat\", baseline=\"custom\", benchmark=y_cs_hat)\n",
    "\n",
    "            # ---------- 2) CSARM (residual = Ridge, TS-CV) ----------\n",
    "            csarm = make_strategy(\n",
    "                \"CSARM\",\n",
    "                target_cols=Y_COLS,\n",
    "                slope_map=slope_map,\n",
    "                feature_cols=feat_cols,          # residual ridge가 보는 feature\n",
    "                residual_kind=\"ridge\",\n",
    "                residual_params=dict(alpha=1.0, random_state=seed),  # alpha는 res_cv에서 override\n",
    "                scale_res=True,\n",
    "                res_cv=RIDGE_CV,\n",
    "            )\n",
    "\n",
    "            runner_csarm = ExpandingRunner(\n",
    "                X=X_cs,     # slope + features\n",
    "                y=y,\n",
    "                strategy=csarm,\n",
    "                period=PERIOD,\n",
    "                burn_in_end=BURN_IN_END,\n",
    "                horizon=HORIZON,\n",
    "            )\n",
    "            runner_csarm.fit_walk(progress=SHOW_PROGRESS, desc=f\"CSARM(ridge) [{tag}] (run={run+1})\")\n",
    "\n",
    "            se_csarm = mse10_from_runner(runner_csarm)\n",
    "            mse_runs_csarm.append(se_csarm)\n",
    "\n",
    "            if run == 0:\n",
    "                print(f\"\\n=== CSARM(ridge) [{tag}] (run=1) ===\")\n",
    "                print(\"R2OOS vs naive:\\n\",    runner_csarm.R2OOS(baseline=\"naive\").round(4))\n",
    "                print(\"R2OOS vs condmean:\\n\", runner_csarm.R2OOS(baseline=\"condmean\").round(4))\n",
    "                print(\"R2OOS vs CS OLS:\\n\",   runner_csarm.R2OOS(baseline=\"custom\", benchmark=y_cs_hat).round(4))\n",
    "\n",
    "                runner_csarm.to_mat(f\"csarm_ridge_{tag}.mat\", baseline=\"custom\", benchmark=y_cs_hat)\n",
    "\n",
    "            # ---------- 3) Plain MLP (hold-out CV) ----------\n",
    "            mlp_params = dict(MLP_PARAMS_BASE)\n",
    "            mlp_params[\"random_state\"] = seed\n",
    "\n",
    "            mlp = make_strategy(\n",
    "                \"MLP\",\n",
    "                target_cols=Y_COLS,\n",
    "                feature_cols=feat_cols,\n",
    "                params=mlp_params,\n",
    "                # 표준화는 외부에서 처리한다고 가정\n",
    "                scale=False,\n",
    "                cv=MLP_CV,\n",
    "            )\n",
    "\n",
    "            runner_mlp = ExpandingRunner(\n",
    "                X=X_feat,\n",
    "                y=y,\n",
    "                strategy=mlp,\n",
    "                period=PERIOD,\n",
    "                burn_in_end=BURN_IN_END,\n",
    "                horizon=HORIZON,\n",
    "            )\n",
    "            runner_mlp.fit_walk(progress=SHOW_PROGRESS, desc=f\"Plain MLP [{tag}] (run={run+1})\")\n",
    "\n",
    "            se_mlp = mse10_from_runner(runner_mlp)\n",
    "            mse_runs_mlp.append(se_mlp)\n",
    "\n",
    "            if run == 0:\n",
    "                print(f\"\\n=== Plain MLP [{tag}] (run=1) ===\")\n",
    "                print(\"R2OOS vs naive:\\n\",    runner_mlp.R2OOS(baseline=\"naive\").round(4))\n",
    "                print(\"R2OOS vs condmean:\\n\", runner_mlp.R2OOS(baseline=\"condmean\").round(4))\n",
    "                print(\"R2OOS vs CS OLS:\\n\",   runner_mlp.R2OOS(baseline=\"custom\", benchmark=y_cs_hat).round(4))\n",
    "\n",
    "                runner_mlp.to_mat(f\"mlp_{tag}.mat\", baseline=\"custom\", benchmark=y_cs_hat)\n",
    "\n",
    "            # ---------- 4) SDMLP (구현에 맞게 사용, 여기서는 CV 미적용) ----------\n",
    "            sdmlp_params = dict(SDMLP_PARAMS_BASE)\n",
    "            sdmlp_params[\"random_state\"] = seed\n",
    "\n",
    "            # SDMLP 전략 구현에서 요구하는 인자에 맞춰 사용\n",
    "            sdmlp = make_strategy(\n",
    "                \"SDMLP\",\n",
    "                target_cols=Y_COLS,\n",
    "                slope_map=slope_map,\n",
    "                feature_cols=feat_cols,   # residual MLP는 fwd/macro 사용\n",
    "                params=sdmlp_params,\n",
    "            )\n",
    "\n",
    "            runner_sdmlp = ExpandingRunner(\n",
    "                X=X_cs,   # slope + features\n",
    "                y=y,\n",
    "                strategy=sdmlp,\n",
    "                period=PERIOD,\n",
    "                burn_in_end=BURN_IN_END,\n",
    "                horizon=HORIZON,\n",
    "            )\n",
    "            runner_sdmlp.fit_walk(progress=SHOW_PROGRESS, desc=f\"SDMLP [{tag}] (run={run+1})\")\n",
    "\n",
    "            se_sdmlp = mse10_from_runner(runner_sdmlp)\n",
    "            mse_runs_sdmlp.append(se_sdmlp)\n",
    "\n",
    "            if run == 0:\n",
    "                print(f\"\\n=== SDMLP [{tag}] (run=1) ===\")\n",
    "                print(\"R2OOS vs naive:\\n\",    runner_sdmlp.R2OOS(baseline=\"naive\").round(4))\n",
    "                print(\"R2OOS vs condmean:\\n\", runner_sdmlp.R2OOS(baseline=\"condmean\").round(4))\n",
    "                print(\"R2OOS vs CS OLS:\\n\",   runner_sdmlp.R2OOS(baseline=\"custom\", benchmark=y_cs_hat).round(4))\n",
    "\n",
    "                runner_sdmlp.to_mat(f\"sdmlp_{tag}.mat\", baseline=\"custom\", benchmark=y_cs_hat)\n",
    "\n",
    "        # ------ run 방향 평균 MSE_10(t) 저장 ------\n",
    "        save_mse10_mean(mse_runs_ridge, f\"ridge_{tag}_mse10_avg.csv\")\n",
    "        save_mse10_mean(mse_runs_csarm, f\"csarm_ridge_{tag}_mse10_avg.csv\")\n",
    "        save_mse10_mean(mse_runs_mlp,   f\"mlp_{tag}_mse10_avg.csv\")\n",
    "        save_mse10_mean(mse_runs_sdmlp, f\"sdmlp_{tag}_mse10_avg.csv\")\n",
    "\n",
    "        print(f\"\\n>>> [{tag}] 평균 MSE_10(t) CSV 저장 완료.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DNN_DUAL rolling:   4%|▍         | 20/520 [03:47<1:34:56, 11.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# ================================= EXPERIMENT: 10-out-of-20 (ARM, macro-MLP) ================================\n",
    "import os, sys, re, json, time, warnings\n",
    "from typing import Dict, Any, List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- framework entrypoint ---\n",
    "from rolling_framework import Machine   # 프로젝트의 핵심 API\n",
    "\n",
    "# ============================ Configs =======================================================================\n",
    "DATA_DIR      = \"data/\"\n",
    "Y_FILE        = os.path.join(DATA_DIR, \"exrets.csv\")\n",
    "SLOPE_FILE    = os.path.join(DATA_DIR, \"slope.csv\")\n",
    "YL_FILE       = os.path.join(DATA_DIR, \"yl_all.csv\")\n",
    "MACRO_FILE    = os.path.join(DATA_DIR, \"MacroFactors.csv\")\n",
    "\n",
    "OUT_DIR       = \"./output\";  os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# 샘플/예측 구간\n",
    "BURN_START, BURN_END   = \"197108\", \"199001\"\n",
    "PERIOD_START, PERIOD_END = \"197108\", \"202312\"\n",
    "HORIZON = 12                           # months ahead\n",
    "\n",
    "MATURITIES = [\"xr_2\",\"xr_3\",\"xr_5\",\"xr_7\",\"xr_10\"]\n",
    "\n",
    "# ============================ Robust scalar helper ==========================================================\n",
    "def _to_scalar(x, agg: str = \"mean\") -> float:\n",
    "    \"\"\"\n",
    "    Robustly convert x (scalar / Series / DataFrame / array / list) to float.\n",
    "    - If vector-like: aggregate with 'mean' (default) or 'sum'.\n",
    "    - If single element: return that element as float.\n",
    "    - On failure: return NaN.\n",
    "    \"\"\"\n",
    "    if x is None:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    if np.isscalar(x):\n",
    "        try:\n",
    "            return float(x)\n",
    "        except Exception:\n",
    "            return float(\"nan\")\n",
    "\n",
    "    if isinstance(x, pd.Series):\n",
    "        if x.size == 1:\n",
    "            return float(x.iloc[0])\n",
    "        vals = x.to_numpy(dtype=float, copy=False)\n",
    "        return float(np.nanmean(vals) if agg == \"mean\" else np.nansum(vals))\n",
    "\n",
    "    if isinstance(x, pd.DataFrame):\n",
    "        vals = x.to_numpy(dtype=float, copy=False)\n",
    "        return float(np.nanmean(vals) if agg == \"mean\" else np.nansum(vals))\n",
    "\n",
    "    try:\n",
    "        arr = np.asarray(x, dtype=float)\n",
    "        if arr.size == 1:\n",
    "            return float(arr.item())\n",
    "        return float(np.nanmean(arr) if agg == \"mean\" else np.nansum(arr))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        return float(x)\n",
    "    except Exception:\n",
    "        return float(\"nan\")\n",
    "\n",
    "# ============================ IO helpers ===================================================================\n",
    "def _load_csv(path, name):\n",
    "    try:\n",
    "        return pd.read_csv(path, index_col=\"Time\")\n",
    "    except FileNotFoundError as e:\n",
    "        sys.exit(f\"[ERROR] missing {name} → {e.filename}\")\n",
    "\n",
    "def _align_time(*dfs):\n",
    "    idx=None\n",
    "    for d in dfs: idx = d.index if idx is None else idx.intersection(d.index)\n",
    "    return [d.loc[idx].sort_index() for d in dfs]\n",
    "\n",
    "def _direct_pairs(slope_cols, y_cols):\n",
    "    mk = lambda s: re.search(r\"(\\d+)\", s).group(1) if re.search(r\"(\\d+)\", s) else None\n",
    "    y_map = {mk(c): c for c in y_cols}\n",
    "    return [(sc, y_map[mk(sc)]) for sc in slope_cols if mk(sc) in y_map]\n",
    "\n",
    "# ============================ Data load =====================================================================\n",
    "y     = _load_csv(Y_FILE,   \"exrets\")\n",
    "slope = _load_csv(SLOPE_FILE, \"slope\")\n",
    "yl    = _load_csv(YL_FILE,   \"yl_all\")\n",
    "macro = _load_csv(MACRO_FILE,\"MacroFactors\")\n",
    "\n",
    "# 타깃 열 필터\n",
    "y_cols = [c for c in MATURITIES if c in y.columns]\n",
    "if not y_cols:\n",
    "    sys.exit(\"[ERROR] MATURITIES not in exrets\")\n",
    "y = y[y_cols]\n",
    "\n",
    "# 시간축 맞추기\n",
    "y, slope, yl, macro = _align_time(y, slope, yl, macro)\n",
    "\n",
    "# slope->y 자동 매핑  ex) slope_2 -> xr_2\n",
    "DIRECT_PAIRS = _direct_pairs(slope.columns, y_cols)\n",
    "\n",
    "print(\"✓ Loaded data shapes:\",\n",
    "      {k:v.shape for k,v in [(\"y\",y),(\"slope\",slope),(\"yl\",yl),(\"macro\",macro)]})\n",
    "print(\"✓ direct map pairs :\", DIRECT_PAIRS)\n",
    "\n",
    "# ============================ Experiment setup ==============================================================\n",
    "# CASE: Base = slope(OLS), Residual = macro(MLP)\n",
    "# X 구성: slope + macro 모두 포함 (베이스/잔차가 같은 X에서 서로 다른 열을 사용)\n",
    "X_macro = pd.concat([slope, macro], axis=1)\n",
    "\n",
    "# 기본 옵션(고정) — 필요 시 여기서만 수정\n",
    "BASE_OPT = {\n",
    "    \"base_on\": True,                          # 베이스 켜기 → CS-Resi 형태\n",
    "    \"base_cols\":   list(slope.columns),       # 베이스는 slope 만 사용\n",
    "    \"target_cols\": list(y.columns),           # ['xr_2','xr_3','xr_5','xr_7','xr_10']\n",
    "    \"residual_kind\": \"mlp\",                   # 잔차학습은 단일 MLP\n",
    "    \"feature_cols\": list(macro.columns),      # 잔차 입력은 macro 만 사용\n",
    "    \"standardize_res\": True,                  # 잔차 입력만 표준화\n",
    "    \"mlp_hidden\": (64, 32),\n",
    "    \"mlp_dropout\": 0.1,\n",
    "    \"mlp_lr\": 1e-3,\n",
    "    \"mlp_wd\": 1e-4,                           # ← L2 (weight decay)\n",
    "    \"mlp_epochs\": 200,\n",
    "    \"mlp_patience\": 20,\n",
    "    \"seed\": 0,                                # seed는 run마다 바꿔줌\n",
    "}\n",
    "\n",
    "# Grid (경량) — 내부 전략이 단일 Grid로 읽어 기본값을 세팅\n",
    "BASE_GRID = {\n",
    "    \"arm__residual_model__module__hidden\": [(64, 32), (128, 64)],\n",
    "    \"arm__residual_model__module__dropout\": [0.0, 0.2],\n",
    "    \"arm__residual_model__optimizer__lr\": [1e-3, 5e-4],\n",
    "    \"arm__residual_model__optimizer__weight_decay\": [0.0, 1e-4],  # ← 꼭 포함(L2)\n",
    "}\n",
    "\n",
    "# ============================ Core run function =============================================================\n",
    "def run_once_and_save(\n",
    "    run_id: str,\n",
    "    X: pd.DataFrame,\n",
    "    y_: pd.DataFrame,\n",
    "    option: Dict[str, Any],\n",
    "    params_grid: Dict[str, List],\n",
    "    burn_in=(BURN_START, BURN_END),\n",
    "    period=(PERIOD_START, PERIOD_END),\n",
    "    horizon=HORIZON,\n",
    "    out_base=OUT_DIR,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    한 번의 rolling 학습을 수행하고, 요약을 저장해 반환.\n",
    "    저장: {out_base}/runs/{run_id}/summary.json\n",
    "    \"\"\"\n",
    "    run_dir = os.path.join(out_base, \"runs\", run_id)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "    # 옵션 복사 및 seed 설정\n",
    "    opt = dict(option)\n",
    "    seed = int(opt.get(\"seed\", 0))\n",
    "    np.random.seed(seed)\n",
    "    try:\n",
    "        import torch\n",
    "        torch.manual_seed(seed)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Machine 생성 및 학습\n",
    "    m = Machine(\n",
    "        X, y_, \"ARM\",\n",
    "        option=opt, params_grid=params_grid,\n",
    "        burn_in_start=burn_in[0], burn_in_end=burn_in[1],\n",
    "        period=[period[0], period[1]], forecast_horizon=horizon\n",
    "    )\n",
    "    print(f\"  - start training (run_id={run_id})\")\n",
    "    t0 = time.time()\n",
    "    m.training()\n",
    "    elapsed = time.time() - t0\n",
    "\n",
    "    # 성능 지표 안전 변환(스칼라)\n",
    "    r2oos_raw = m.R2OOS()\n",
    "    mseoos_raw = m.MSEOOS()\n",
    "    r2oos = _to_scalar(r2oos_raw, agg=\"mean\")\n",
    "    mseoos = _to_scalar(mseoos_raw, agg=\"mean\")\n",
    "\n",
    "    # 그리드 최적 파라미터 접근 (있을 경우)\n",
    "    try:\n",
    "        best_params = getattr(m.strategy, \"best_params_\", None)\n",
    "        if best_params is None and hasattr(m.strategy, \"last_best_params_\"):\n",
    "            best_params = m.strategy.last_best_params_\n",
    "    except Exception:\n",
    "        best_params = None\n",
    "\n",
    "    # 요약 저장 (JSON 직렬화 안전)\n",
    "    def _jsonable(v):\n",
    "        if isinstance(v, (np.floating,)):\n",
    "            return float(v)\n",
    "        if isinstance(v, (np.integer,)):\n",
    "            return int(v)\n",
    "        if isinstance(v, (np.ndarray,)):\n",
    "            return v.tolist()\n",
    "        return v\n",
    "\n",
    "    summary = {\n",
    "        \"run_id\": run_id,\n",
    "        \"elapsed_sec\": round(float(elapsed), 2),\n",
    "        \"R2OOS\": float(r2oos),\n",
    "        \"MSEOOS\": float(mseoos),\n",
    "        \"best_params\": {k: _jsonable(v) for k, v in (best_params or {}).items()},\n",
    "    }\n",
    "    with open(os.path.join(run_dir, \"summary.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(summary, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return summary\n",
    "\n",
    "# ============================ 20 runs + pick top-10 =========================================================\n",
    "def run_20_and_ensemble_top10():\n",
    "    print(\"\\n▶ 20 runs start (ARM: base=slope OLS, residual=macro-MLP)\")\n",
    "    summaries = []\n",
    "\n",
    "    # 20회 반복 (seed 1..20)\n",
    "    for k, seed in enumerate(range(1, 21), start=1):\n",
    "        opt = dict(BASE_OPT)\n",
    "        opt[\"seed\"] = seed\n",
    "        run_id = f\"ARM_macroMLP_seed{seed}\"\n",
    "\n",
    "        print(f\"  - run {k:02d}/20 (seed={seed})\")\n",
    "        summ = run_once_and_save(\n",
    "            run_id=run_id,\n",
    "            X=X_macro,\n",
    "            y_=y,\n",
    "            option=opt,\n",
    "            params_grid=BASE_GRID,\n",
    "            burn_in=(BURN_START, BURN_END),\n",
    "            period=(PERIOD_START, PERIOD_END),\n",
    "            horizon=HORIZON,\n",
    "            out_base=OUT_DIR,\n",
    "        )\n",
    "        print(f\"    R2OOS={summ['R2OOS']:.6f}  MSEOOS={summ['MSEOOS']:.6f}\")\n",
    "        summaries.append(summ)\n",
    "\n",
    "    # 결과 집계 / 저장\n",
    "    df = pd.DataFrame(summaries)\n",
    "    for col in [\"R2OOS\", \"MSEOOS\", \"elapsed_sec\"]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    df_sorted = df.sort_values(\"R2OOS\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    csv_path = os.path.join(OUT_DIR, \"runs_summary.csv\")\n",
    "    df_sorted.to_csv(csv_path, index=False)\n",
    "    print(f\"\\n✓ Saved summary table → {csv_path}\")\n",
    "\n",
    "    # 상위 10개 출력\n",
    "    top10 = df_sorted.head(10)\n",
    "    print(\"\\nTop-10 by R2OOS:\")\n",
    "    print(top10[[\"run_id\", \"R2OOS\", \"MSEOOS\", \"elapsed_sec\"]])\n",
    "\n",
    "    # (선택) 상위 10개 run_id 리스트 반환\n",
    "    return top10[\"run_id\"].tolist()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_20_and_ensemble_top10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

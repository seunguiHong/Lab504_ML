{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ OLS-SL_nonDNN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OLS rolling:  93%|█████████▎| 485/520 [00:08<00:00, 59.08it/s]"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "run_models_no_dnn.py  ─ period-agnostic runner (NON-DNN)\n",
    "=======================================================\n",
    "\n",
    "· Linear / penalised / dimension-reduced / tree-based models  \n",
    "· **No `--period` argument** – `DATA_ROOT` 안의 CSV 파일만 있으면 바로 실행\n",
    "\n",
    "Typical usage\n",
    "-------------\n",
    "$ python run_models_no_dnn.py                      # CPU, default tag\n",
    "$ python run_models_no_dnn.py --tag MYRUN          # custom tag in filenames\n",
    "$ python run_models_no_dnn.py --out ./foo.csv      # explicit CSV path\n",
    "\n",
    "Author : Seungui Hong · 2025-07-08\n",
    "\"\"\"\n",
    "# ─────────────────────────────────────────────────────────────── imports ──\n",
    "import argparse, os, sys, warnings, joblib, datetime as dt\n",
    "import pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from rolling_framework import Machine                 # in-house wrapper\n",
    "\n",
    "# ───────────────────────────────────────────────────── user configuration ──\n",
    "DATA_ROOT      = \"/Users/ethan_hong/Dropbox/0_Lab_504/Codes/504_ML/LABORATORY/data\"   # CSV directory\n",
    "OUTPUT_ROOT    = \"/Users/ethan_hong/Dropbox/0_Lab_504/Codes/504_ML/LABORATORY/code_output\" # results + pkl sub-dir\n",
    "RESULTS_TAG = \"nonDNN\"                # default filename tag\n",
    "\n",
    "BURN_IN_START = \"197108\"\n",
    "BURN_IN_END   = \"198009\"\n",
    "PERIOD_START  = \"199009\"\n",
    "PERIOD_END    = \"202312\"\n",
    "OFFSET        = 12                    # months ahead\n",
    "\n",
    "PORTFOLIO_WEIGHTS = (\n",
    "    pd.Series({\"xr_2\": 2, \"xr_5\": 5, \"xr_7\": 7, \"xr_10\": 10}, name=\"w\")\n",
    "    .pipe(lambda s: s / s.sum())\n",
    ")\n",
    "COLS_DW = PORTFOLIO_WEIGHTS.index.tolist()\n",
    "\n",
    "# ───────────────────────────────────────────── predictor blocks & grids ──\n",
    "PREDICTOR_SETS = [\n",
    "    (\"SL\", lambda d: d[\"SL\"][[\"slope\"]]),\n",
    "    (\"CP\", lambda d: d[\"CP\"]),\n",
    "    (\"F6\", lambda d: d[\"F6\"]),\n",
    "]\n",
    "\n",
    "param_grid_rf = {\n",
    "    \"model__estimator__n_estimators\":      [300],\n",
    "    \"model__estimator__max_depth\":         [2, 8],\n",
    "    \"model__estimator__min_samples_split\": [2, 4],\n",
    "    \"model__estimator__min_samples_leaf\":  [1, 2, 4],\n",
    "    \"model__estimator__max_features\":      [0.25, 0.5, 1.0],\n",
    "}\n",
    "param_grid_et = {\n",
    "    \"model__estimator__n_estimators\":      [300],\n",
    "    \"model__estimator__max_depth\":         [None, 8],\n",
    "    \"model__estimator__min_samples_split\": [2, 4],\n",
    "    \"model__estimator__min_samples_leaf\":  [1, 2, 4],\n",
    "    \"model__estimator__max_features\":      [0.25, 0.5, 1.0],\n",
    "    \"model__estimator__bootstrap\":         [False],\n",
    "}\n",
    "param_grid_xgb = {\n",
    "    # \"model__estimator__tree_method\": [\"gpu_hist\"],\n",
    "    \"model__estimator__n_estimators\":  [300],\n",
    "    \"model__estimator__max_depth\":     [2, 4],\n",
    "    \"model__estimator__learning_rate\": [0.01],\n",
    "    \"model__estimator__subsample\":     [0.7, 0.5],\n",
    "    \"model__estimator__reg_lambda\":    [0.1, 1.0],\n",
    "}\n",
    "param_grid_lasso      = {\"reg__alpha\": [0.001, 1.0]}\n",
    "param_grid_ridge      = {\"reg__alpha\": [0.001, 1.0]}\n",
    "param_grid_elasticnet = {\"reg__alpha\": [0.01, 0.1, 1, 10],\n",
    "                         \"reg__l1_ratio\": [0.1, 0.3, 0.5]}\n",
    "\n",
    "MODEL_SPECS = [\n",
    "    (\"OLS\",        dict(model_type=\"OLS\",       option=None,          params=None)),\n",
    "    (\"Ridge\",      dict(model_type=\"Penalized\", option=\"ridge\",       params=param_grid_ridge)),\n",
    "    (\"Lasso\",      dict(model_type=\"Penalized\", option=\"lasso\",       params=param_grid_lasso)),\n",
    "    (\"ElasticNet\", dict(model_type=\"Penalized\", option=\"elasticnet\",  params=param_grid_elasticnet)),\n",
    "    (\"RandomForest\",dict(model_type=\"Tree\",     option=\"RandomForest\",params=param_grid_rf)),\n",
    "    (\"ExtraTrees\", dict(model_type=\"Tree\",     option=\"ExtraTrees\",  params=param_grid_et)),\n",
    "    (\"XGBoost\",    dict(model_type=\"Tree\",     option=\"XGB\",         params=param_grid_xgb)),\n",
    "]\n",
    "\n",
    "# ───────────────────────────────────────────────────────── data loading ──\n",
    "def load_data() -> tuple[pd.DataFrame, dict]:\n",
    "    \"\"\"Read CSVs directly from DATA_ROOT (no per-period sub-folder).\"\"\"\n",
    "    try:\n",
    "        y = pd.read_csv(f\"{DATA_ROOT}/exrets.csv\", index_col=\"Time\")[\n",
    "            [\"xr_2\", \"xr_5\", \"xr_7\", \"xr_10\"]\n",
    "        ]\n",
    "        data = {\n",
    "            \"FWDS\":  pd.read_csv(f\"{DATA_ROOT}/fwds.csv\",         index_col=\"Time\"),\n",
    "            \"MACV\":  pd.read_csv(f\"{DATA_ROOT}/MacroFactors.csv\", index_col=\"Time\"),\n",
    "            \"LSC\":   pd.read_csv(f\"{DATA_ROOT}/lsc.csv\",          index_col=\"Time\"),\n",
    "            # \"RVOL\":  pd.read_csv(f\"{DATA_ROOT}/real_vol.csv\",     index_col=\"Time\"),\n",
    "            \"CP\":    pd.read_csv(f\"{DATA_ROOT}/cp.csv\",           index_col=\"Time\"),\n",
    "        }\n",
    "    except FileNotFoundError as e:\n",
    "        sys.exit(f\"[ERROR] CSV 파일을 찾을 수 없습니다 → {e.filename}\\n\"\n",
    "                 f\"DATA_ROOT 경로를 확인하세요.\")\n",
    "\n",
    "    # derived groups\n",
    "    data[\"F6\"] = data[\"MACV\"][[\"F1\", \"F2\", \"F3\", \"F4\", \"F8\", \"F1^3\"]]\n",
    "    data[\"SL\"] = data[\"LSC\"][[\"slope\"]]\n",
    "    return y, data\n",
    "\n",
    "# ─────────────────────────────────────────────── training / metric row ──\n",
    "def run_single_model(X, y, tag, spec):\n",
    "    m = Machine(\n",
    "        X, y,\n",
    "        spec[\"model_type\"],\n",
    "        option           = spec[\"option\"],\n",
    "        params_grid      = spec[\"params\"],\n",
    "        burn_in_start    = BURN_IN_START,\n",
    "        burn_in_end      = BURN_IN_END,\n",
    "        period           = [PERIOD_START, PERIOD_END],\n",
    "        forecast_horizon = OFFSET,\n",
    "    )\n",
    "    m.training()\n",
    "\n",
    "    # ── (A) 모델 저장 : last_model_이 있을 때만 --------------------------\n",
    "    model_obj = getattr(m.strategy, \"last_model_\", None)\n",
    "    if model_obj is not None:\n",
    "        pkl_dir = os.path.join(OUTPUT_ROOT, \"pkl\")\n",
    "        os.makedirs(pkl_dir, exist_ok=True)\n",
    "        joblib.dump(model_obj, os.path.join(pkl_dir, f\"{tag}.pkl\"))\n",
    "    else:\n",
    "        print(f\"[WARN] {tag} : 'last_model_' 속성이 없어 .pkl 저장을 건너뜀\")\n",
    "\n",
    "    # ── (B) 메트릭 수집 ----------------------------------------------------\n",
    "    r2 = m.R2OOS()\n",
    "    return {\n",
    "        \"model\"     : tag,\n",
    "        \"r2_xr_2\"   : r2[\"xr_2\"],\n",
    "        \"r2_xr_5\"   : r2[\"xr_5\"],\n",
    "        \"r2_xr_7\"   : r2[\"xr_7\"],\n",
    "        \"r2_xr_10\"  : r2[\"xr_10\"],\n",
    "        \"port_R2_EW\": m.r2_oos_portfolio(),\n",
    "        \"port_R2_DW\": m.r2_oos_portfolio(cols=COLS_DW,\n",
    "                                         weights=PORTFOLIO_WEIGHTS),\n",
    "    }\n",
    "# ──────────────────────────────────────────────────────────────── main ──\n",
    "def main() -> None:\n",
    "    ap = argparse.ArgumentParser(\"Run NON-DNN models & export CSV/PKL\")\n",
    "    ap.add_argument(\"--tag\", default=RESULTS_TAG,\n",
    "                    help=\"tag appended to filenames (default=nonDNN)\")\n",
    "    ap.add_argument(\"--out\", default=None,\n",
    "                    help=\"explicit CSV path (overrides default naming)\")\n",
    "    args, _ = ap.parse_known_args()          # ignore Jupyter-injected flags\n",
    "\n",
    "    # ensure dirs\n",
    "    os.makedirs(OUTPUT_ROOT,            exist_ok=True)\n",
    "    os.makedirs(os.path.join(OUTPUT_ROOT, \"pkl\"), exist_ok=True)\n",
    "\n",
    "    # load once\n",
    "    y, data_blocks = load_data()\n",
    "\n",
    "    rows = []\n",
    "    for set_name, extractor in PREDICTOR_SETS:\n",
    "        X = extractor(data_blocks)\n",
    "        for model_code, spec in MODEL_SPECS:\n",
    "            tag = f\"{model_code}-{set_name}_{args.tag}\"\n",
    "            print(f\"▶ {tag}\")\n",
    "            rows.append(run_single_model(X, y, tag, spec))\n",
    "\n",
    "    res = pd.DataFrame(rows)\n",
    "\n",
    "    # final CSV name\n",
    "    timestamp = dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    csv_path = args.out or os.path.join(\n",
    "        OUTPUT_ROOT, f\"results_{args.tag}_{timestamp}.csv\"\n",
    "    )\n",
    "    res.to_csv(csv_path, index=False)\n",
    "    print(f\"\\n★ Saved {len(res)} rows → {csv_path}\")\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────────────────\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

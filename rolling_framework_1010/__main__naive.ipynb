{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Simple MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= QUIET HEADER (경고 최소화; 맨 위에 두기) =================\n",
    "import sys, types, warnings\n",
    "try:\n",
    "    import tqdm as _tqdm\n",
    "    _auto = types.ModuleType(\"tqdm.auto\"); _auto.tqdm = _tqdm.tqdm\n",
    "    sys.modules[\"tqdm.auto\"] = _auto\n",
    "except Exception:\n",
    "    pass\n",
    "from sklearn.exceptions import DataConversionWarning, ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=DataConversionWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\".*IProgress not found.*\")\n",
    "warnings.filterwarnings(\"ignore\", message=\".*Maximum iterations.*hasn't converged.*\")\n",
    "# ===========================================================================\n",
    "\n",
    "# ================= USER CONFIG =============================================\n",
    "DATA_FILE     = \"dataset.csv\"               # index='Time'\n",
    "Y_COLS        = [\"xr_2\",\"xr_3\",\"xr_5\",\"xr_7\",\"xr_10\"]\n",
    "\n",
    "SLOPE_PREFIX  = \"s_\"                        # 예: s_2, s_3, ...\n",
    "MACRO_PREFIX  = \"F\"                         # 예: FIP, FUMD, F... 등 'F'로 시작\n",
    "FWD_PREFIX    = \"fwd_\"                      # 예: fwd_1, fwd_2, ...\n",
    "\n",
    "PERIOD        = [\"197108\", \"202312\"]\n",
    "BURN_IN_END   = \"199001\"\n",
    "HORIZON       = 12\n",
    "SHOW_PROGRESS = True\n",
    "\n",
    "RUN_RIDGE     = True\n",
    "RUN_MLP       = True\n",
    "\n",
    "# 자주 바꿀만한 최소 파라미터/그리드만 노출\n",
    "RIDGE_PARAMS  = dict(random_state=0)        # alpha는 그리드에서 튜닝\n",
    "RIDGE_CV      = {\"mode\":\"tscv\",\"n_splits\":10,\"grid\":{\"alpha\":[1e-3,1e-2,1e-1,1,10,100]}}\n",
    "\n",
    "MLP_PARAMS    = dict(                        # 고정 기본값(필요시만 수정)\n",
    "    random_state=0,\n",
    "    max_iter=2000,\n",
    "    early_stopping=True,\n",
    "    learning_rate_init=1e-3,\n",
    "    tol=1e-5,\n",
    ")\n",
    "MLP_CV        = {\"mode\":\"tscv\",\"n_splits\":8,\n",
    "                 \"grid\":{\"hidden_layer_sizes\":[(16,), (16, 8)], \"alpha\":[1e3, 1e5, 1e7]}}\n",
    "# ===========================================================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from rolling_framework import ExpandingRunner, make_strategy\n",
    "\n",
    "# ----------------------- helpers -----------------------\n",
    "def read_df(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, index_col=\"Time\"); df.index = df.index.astype(str)\n",
    "    return df\n",
    "\n",
    "def cols_by_prefix(df: pd.DataFrame, prefix: str) -> pd.DataFrame:\n",
    "    return df.loc[:, df.columns.str.startswith(prefix)]\n",
    "\n",
    "def make_features(df: pd.DataFrame, *, use_slope: bool, use_macro: bool, use_fwd: bool) -> pd.DataFrame:\n",
    "    parts = []\n",
    "    if use_slope: parts.append(cols_by_prefix(df, SLOPE_PREFIX))\n",
    "    if use_macro: parts.append(cols_by_prefix(df, MACRO_PREFIX))\n",
    "    if use_fwd:   parts.append(cols_by_prefix(df, FWD_PREFIX))\n",
    "    if not parts: raise ValueError(\"No features selected.\")\n",
    "    X = pd.concat(parts, axis=1)\n",
    "    return X.loc[:, ~X.columns.duplicated(keep=\"first\")]  # 중복 제거\n",
    "\n",
    "def slope_map_from_targets(df: pd.DataFrame, ycols, slope_prefix: str):\n",
    "    suffix     = [c.split(\"_\", 1)[1] for c in ycols]\n",
    "    slope_cols = [f\"{slope_prefix}{s}\" for s in suffix]\n",
    "    missing = [c for c in slope_cols if c not in df.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Missing slope columns: {missing}\")\n",
    "    return dict(zip(ycols, slope_cols))\n",
    "\n",
    "def build_cs_baseline(runner: ExpandingRunner, df: pd.DataFrame, y: pd.DataFrame,\n",
    "                      slope_map: dict) -> pd.DataFrame:\n",
    "    \"\"\"y_cshat: 각 만기 j에서 xr_j ~ s_j OLS, expanding-OOS 예측\"\"\"\n",
    "    rows = []\n",
    "    for t in runner.test_times:\n",
    "        tr = [s for s in runner.times if s < t]\n",
    "        if not tr: \n",
    "            continue\n",
    "        row = {}\n",
    "        for ycol, scol in slope_map.items():\n",
    "            X_tr = df.loc[tr, [scol]].astype(float)             # DF로 fit\n",
    "            y_tr = y.loc[tr, ycol].astype(float).values\n",
    "            reg  = LinearRegression().fit(X_tr, y_tr)\n",
    "            x_te = pd.DataFrame([[df.loc[t, scol]]], columns=[scol], dtype=float)  # DF로 predict\n",
    "            row[ycol] = float(reg.predict(x_te))\n",
    "        rows.append(pd.Series(row, name=t))\n",
    "    return pd.DataFrame(rows).reindex(index=runner.test_times, columns=list(slope_map.keys()))\n",
    "\n",
    "def run_experiment(model_name: str, params: dict, cv: dict,\n",
    "                   X: pd.DataFrame, y: pd.DataFrame, tag: str, scale: bool = True):\n",
    "    strat  = make_strategy(model_name, target_cols=Y_COLS, params=params, scale=scale, cv=cv)\n",
    "    runner = ExpandingRunner(X=X, y=y, strategy=strat,\n",
    "                             period=PERIOD, burn_in_end=BURN_IN_END, horizon=HORIZON)\n",
    "    runner.fit_walk(progress=SHOW_PROGRESS, desc=f\"{model_name} on {tag}\")\n",
    "\n",
    "    # Custom benchmark: y_cshat (CS OLS baseline)\n",
    "    s_map    = slope_map_from_targets(df, Y_COLS, SLOPE_PREFIX)\n",
    "    y_cshat  = build_cs_baseline(runner, df, y, s_map)\n",
    "\n",
    "    r2_naive = runner.R2OOS(baseline=\"naive\").round(4)\n",
    "    r2_cond  = runner.R2OOS(baseline=\"condmean\").round(4)\n",
    "    r2_cs    = runner.R2OOS(baseline=\"custom\", benchmark=y_cshat).round(4)\n",
    "\n",
    "    print(f\"\\n=== {model_name} on {tag} ===\")\n",
    "    print(\"R2OOS vs naive:\\n\",     r2_naive)\n",
    "    print(\"R2OOS vs condmean:\\n\",  r2_cond)\n",
    "    print(\"R2OOS vs CS OLS(y_cshat):\\n\", r2_cs)\n",
    "\n",
    "    # 필요하면 저장 (주석 해제)\n",
    "    # runner.to_mat(f\"{model_name.lower()}_{tag.replace(' ','_').lower()}.mat\",\n",
    "    #               baseline=\"custom\", benchmark=y_cshat)\n",
    "    # y_cshat.to_csv(f\"ycshat_{tag.replace(' ','_').lower()}.csv\")\n",
    "\n",
    "    return runner, y_cshat\n",
    "\n",
    "# ----------------------- load & split -------------------\n",
    "df = read_df(DATA_FILE)\n",
    "y  = df[Y_COLS].copy()\n",
    "\n",
    "# 두 실험용 특징세트\n",
    "X_slope_fwd        = make_features(df, use_slope=True, use_macro=False, use_fwd=True)\n",
    "X_slope_macro_fwd  = make_features(df, use_slope=True, use_macro=True,  use_fwd=True)\n",
    "\n",
    "# ----------------------- RUN: Ridge ---------------------\n",
    "if RUN_RIDGE:\n",
    "    _runner, _ycshat = run_experiment(\"Ridge\", RIDGE_PARAMS, RIDGE_CV, X_slope_fwd,       y, \"Slope + Fwd\",           scale=True)\n",
    "    _runner, _ycshat = run_experiment(\"Ridge\", RIDGE_PARAMS, RIDGE_CV, X_slope_macro_fwd, y, \"Slope + Macro + Fwd\",   scale=True)\n",
    "\n",
    "# ----------------------- RUN: MLP -----------------------\n",
    "if RUN_MLP:\n",
    "    _runner, _ycshat = run_experiment(\"MLP\", MLP_PARAMS, MLP_CV, X_slope_fwd,       y, \"Slope + Fwd\",         scale=True)\n",
    "    _runner, _ycshat = run_experiment(\"MLP\", MLP_PARAMS, MLP_CV, X_slope_macro_fwd, y, \"Slope + Macro + Fwd\", scale=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

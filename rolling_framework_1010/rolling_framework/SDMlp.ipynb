{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slope Directly Connected MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================= QUIET HEADER =================\n",
    "import sys, types, warnings\n",
    "try:\n",
    "    import tqdm as _tqdm\n",
    "    _auto = types.ModuleType(\"tqdm.auto\"); _auto.tqdm = _tqdm.tqdm\n",
    "    sys.modules[\"tqdm.auto\"] = _auto\n",
    "except Exception:\n",
    "    pass\n",
    "from sklearn.exceptions import DataConversionWarning, ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=DataConversionWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\".*IProgress not found.*\")\n",
    "# =================================================\n",
    "\n",
    "# ================= USER CONFIG ===================\n",
    "DATA_FILE     = \"dataset.csv\"                 # index='Time'\n",
    "Y_COLS        = [\"xr_2\",\"xr_3\",\"xr_5\",\"xr_7\",\"xr_10\"]\n",
    "SLOPE_PREFIX  = \"s_\"\n",
    "FWD_PREFIX    = \"fwd_\"\n",
    "MACRO_PREFIX  = \"F\"\n",
    "\n",
    "PERIOD        = [\"197108\", \"202312\"]\n",
    "BURN_IN_END   = \"199001\"\n",
    "HORIZON       = 12\n",
    "SHOW_PROGRESS = True\n",
    "\n",
    "# MLP(네트워크 가지) 기본값: 자주 바꿀 것만 명시\n",
    "MLP_PARAMS = dict(\n",
    "    random_state=0,\n",
    "    max_iter=2000,\n",
    "    early_stopping=True,\n",
    "    learning_rate_init=1e-3,\n",
    "    tol=1e-5,\n",
    ")\n",
    "\n",
    "# CV 그리드: 네트워크 하이퍼 + (옵션) slope_scale까지 동시 탐색\n",
    "MLP_CV = {\n",
    "    \"mode\": \"tscv\",\n",
    "    \"n_splits\": 8,\n",
    "    \"grid\": {\n",
    "        \"hidden_layer_sizes\": [(16,), (16, 8)],\n",
    "        \"alpha\": [1e3, 1e5, 1e7],\n",
    "    },\n",
    "    # ↓ 있으면 step-CV 때 slope_scale도 함께 탐색(없으면 고정값 사용)\n",
    "    # \"slope_scale\": [1.0, 0.9, 0.8],   # 원치 않으면 이 줄 삭제/주석\n",
    "}\n",
    "\n",
    "# 슬로프 가지 동결/느린 업데이트 제어\n",
    "FREEZE_SLOPE = True     # True면 완전 동결\n",
    "EMA_RHO      = 0.0      # 0이면 동결과 동일, 0<rho<1이면 느린 업데이트\n",
    "FIXED_SLOPE_SCALE = 1.0 # CV로 탐색하지 않을 때 사용(스칼라 or {ycol: float})\n",
    "\n",
    "# 저장 옵션\n",
    "SAVE_MAT   = True\n",
    "MAT_PATH_1 = \"slopeskip_mlp_fwd.mat\"\n",
    "MAT_PATH_2 = \"slopeskip_mlp_fwd_macro.mat\"\n",
    "# =================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "from scipy.io import savemat\n",
    "\n",
    "from rolling_framework import ExpandingRunner\n",
    "from rolling_framework.strategies import Strategy\n",
    "\n",
    "\n",
    "# ------------------- helpers -------------------\n",
    "def read_df(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, index_col=\"Time\"); df.index = df.index.astype(str)\n",
    "    return df\n",
    "\n",
    "def cols_by_prefix(df: pd.DataFrame, prefix: str) -> pd.DataFrame:\n",
    "    return df.loc[:, df.columns.str.startswith(prefix)]\n",
    "\n",
    "def make_features(df: pd.DataFrame, *, use_slope: bool, use_macro: bool, use_fwd: bool) -> pd.DataFrame:\n",
    "    parts=[]\n",
    "    if use_slope: parts.append(cols_by_prefix(df, SLOPE_PREFIX))\n",
    "    if use_macro: parts.append(cols_by_prefix(df, MACRO_PREFIX))\n",
    "    if use_fwd:   parts.append(cols_by_prefix(df, FWD_PREFIX))\n",
    "    if not parts: raise ValueError(\"No features selected.\")\n",
    "    X = pd.concat(parts, axis=1)\n",
    "    return X.loc[:, ~X.columns.duplicated(keep=\"first\")]\n",
    "\n",
    "def slope_map_from_targets(df: pd.DataFrame, ycols: List[str], prefix: str) -> Dict[str, str]:\n",
    "    suf = [c.split(\"_\",1)[1] for c in ycols]\n",
    "    mapping = {yc: f\"{prefix}{s}\" for yc,s in zip(ycols, suf)}\n",
    "    miss = [c for c in mapping.values() if c not in df.columns]\n",
    "    if miss: raise KeyError(f\"Missing slope columns: {miss}\")\n",
    "    return mapping\n",
    "\n",
    "def cs_baseline(times, all_times, df, y, slope_map: Dict[str,str]) -> pd.DataFrame:\n",
    "    rows=[]\n",
    "    for t in times:\n",
    "        tr=[s for s in all_times if s<t]\n",
    "        if not tr: continue\n",
    "        row={}\n",
    "        for ycol,scol in slope_map.items():\n",
    "            X_tr=df.loc[tr,[scol]].astype(float)\n",
    "            y_tr=y.loc[tr,ycol].astype(float).values\n",
    "            reg=LinearRegression().fit(X_tr, y_tr)\n",
    "            x_te=pd.DataFrame([[df.loc[t,scol]]], columns=[scol], dtype=float)\n",
    "            row[ycol]=float(reg.predict(x_te))\n",
    "        rows.append(pd.Series(row, name=t))\n",
    "    return pd.DataFrame(rows).reindex(index=times, columns=list(slope_map.keys()))\n",
    "\n",
    "def save_mat_with_components(path: str, runner: ExpandingRunner, y_cs_hat: pd.DataFrame):\n",
    "    Y_true, Y_pred = runner.collect_frames()\n",
    "    # y_net_hat = total - cs\n",
    "    y_net_hat = (Y_pred - y_cs_hat).reindex_like(Y_pred)\n",
    "    savemat(path, {\n",
    "        \"Y_true\": Y_true.to_numpy(float),\n",
    "        \"Y_pred\": Y_pred.to_numpy(float),\n",
    "        \"Y_cs_hat\": y_cs_hat.to_numpy(float),\n",
    "        \"Y_net_hat\": y_net_hat.to_numpy(float),\n",
    "        \"dates\":  np.array(Y_true.index.tolist(), dtype=object),\n",
    "        \"maturities\": np.array(Y_true.columns.tolist(), dtype=object),\n",
    "        \"horizon\": np.array([runner.horizon]),\n",
    "        \"burn_in_end\": np.array([runner.burn_in_end], dtype=object),\n",
    "    })\n",
    "\n",
    "\n",
    "# ----------- Slope-skip + MLP custom Strategy -----------\n",
    "class SlopeSkipMLPStrategy(Strategy):\n",
    "    \"\"\"\n",
    "    y_hat = (a_j + b_j * slope_j * scale_j) + MLP(other_features).\n",
    "    - (a_j,b_j): 학습구간 OLS. FREEZE/EMA/scale 지원.\n",
    "    - step-CV: MLP grid + (옵션) slope_scale grid 동시 탐색.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        target_cols: List[str],\n",
    "        slope_map: Dict[str, str],\n",
    "        feature_cols: List[str],\n",
    "        mlp_params: Dict,\n",
    "        mlp_cv: Optional[Dict] = None,\n",
    "        freeze_slope: bool = True,\n",
    "        ema_rho: float = 0.0,\n",
    "        slope_scale: float | Dict[str, float] = 1.0,\n",
    "        scale_features: bool = True,\n",
    "    ):\n",
    "        super().__init__(target_cols)\n",
    "        self.slope_map    = dict(slope_map)\n",
    "        self.feature_cols = list(feature_cols)\n",
    "        self.mlp_params   = dict(mlp_params)\n",
    "        self.mlp_cv       = mlp_cv\n",
    "        self.freeze_slope = bool(freeze_slope)\n",
    "        self.ema_rho      = float(ema_rho)\n",
    "        self.slope_scale  = slope_scale\n",
    "        self.scale_features = bool(scale_features)\n",
    "\n",
    "        self._prev_a: Dict[str,float] = {}\n",
    "        self._prev_b: Dict[str,float] = {}\n",
    "\n",
    "    # --- utils ---\n",
    "    def _scale_for(self, ycol: str, maybe_scale) -> float:\n",
    "        if isinstance(maybe_scale, dict):\n",
    "            return float(maybe_scale.get(ycol, 1.0))\n",
    "        return float(maybe_scale)\n",
    "\n",
    "    def _ols_ab(self, Xs: pd.DataFrame, ytr: pd.DataFrame) -> Dict[str,tuple]:\n",
    "        out={}\n",
    "        for ycol, scol in self.slope_map.items():\n",
    "            reg=LinearRegression().fit(Xs[[scol]].to_numpy(float), ytr[ycol].to_numpy(float))\n",
    "            a=float(reg.intercept_); b=float(reg.coef_.ravel()[0])\n",
    "            if (self.ema_rho>0) and (ycol in self._prev_b) and (not self.freeze_slope):\n",
    "                a=(1-self.ema_rho)*a + self.ema_rho*self._prev_a[ycol]\n",
    "                b=(1-self.ema_rho)*b + self.ema_rho*self._prev_b[ycol]\n",
    "            out[ycol]=(a,b)\n",
    "        self._prev_a={k:v[0] for k,v in out.items()}\n",
    "        self._prev_b={k:v[1] for k,v in out.items()}\n",
    "        return out\n",
    "\n",
    "    def _make_mlp_pipe(self, params: Dict) -> Pipeline:\n",
    "        est=MLPRegressor(**{**self.mlp_params, **params})\n",
    "        steps=([(\"scaler\", StandardScaler())] if self.scale_features else []) + [(\"model\", est)]\n",
    "        return Pipeline(steps)\n",
    "\n",
    "    def _tscv(self, n:int, n_splits:int) -> List[tuple]:\n",
    "        test_size=max(1, n//(n_splits+1))\n",
    "        splits=[]\n",
    "        for k in range(n_splits):\n",
    "            tr_end = n - (n_splits-k)*test_size\n",
    "            tr_end = max(1, tr_end)\n",
    "            va_s, va_e = tr_end, min(n, tr_end+test_size)\n",
    "            if va_e-va_s>0: splits.append((np.arange(0,tr_end), np.arange(va_s,va_e)))\n",
    "        return splits\n",
    "\n",
    "    # --- core ---\n",
    "    def fit_predict(self, X_tr: pd.DataFrame, y_tr: pd.DataFrame, x_te: pd.Series) -> pd.Series:\n",
    "        Xs_tr = X_tr[list(self.slope_map.values())]\n",
    "        ab    = self._ols_ab(Xs_tr, y_tr[self.target_cols])\n",
    "\n",
    "        # 네트워크 가지가 있으면 step-CV\n",
    "        if self.feature_cols:\n",
    "            Xf_tr = X_tr[self.feature_cols]\n",
    "            n = len(Xf_tr)\n",
    "            # CV 설정\n",
    "            if self.mlp_cv and self.mlp_cv.get(\"grid\"):\n",
    "                n_splits = int(self.mlp_cv.get(\"n_splits\", 5))\n",
    "                splits   = self._tscv(n, n_splits)\n",
    "                grid     = list(ParameterGrid(self.mlp_cv[\"grid\"]))\n",
    "                scales   = self.mlp_cv.get(\"slope_scale\", [self.slope_scale])\n",
    "                best=(np.inf, None, None)  # (mse, params, scale_choice)\n",
    "\n",
    "                for sc in scales:\n",
    "                    # 타깃 재계산: y - (a + b*s*scale)\n",
    "                    Yt = []\n",
    "                    for ycol, scol in self.slope_map.items():\n",
    "                        a,b = ab[ycol]; k = self._scale_for(ycol, sc)\n",
    "                        Yt.append(y_tr[ycol].to_numpy(float) - (a + k*b*Xs_tr[scol].to_numpy(float)))\n",
    "                    Yt = pd.DataFrame(np.column_stack(Yt), index=Xf_tr.index, columns=self.target_cols)\n",
    "\n",
    "                    for params in grid:\n",
    "                        fold=[]\n",
    "                        for tr_idx, va_idx in splits:\n",
    "                            pipe = self._make_mlp_pipe(params)\n",
    "                            pipe.fit(Xf_tr.iloc[tr_idx], Yt.iloc[tr_idx])\n",
    "                            pred = pipe.predict(Xf_tr.iloc[va_idx])\n",
    "                            mse  = float(np.mean((Yt.iloc[va_idx].to_numpy(float) - pred)**2))\n",
    "                            fold.append(mse)\n",
    "                        m = float(np.mean(fold)) if fold else np.inf\n",
    "                        if m < best[0]:\n",
    "                            best = (m, params, sc)\n",
    "\n",
    "                best_params, best_scale = best[1], best[2]\n",
    "                # 최적 스케일로 전체 적합\n",
    "                Yt_full=[]\n",
    "                for ycol, scol in self.slope_map.items():\n",
    "                    a,b = ab[ycol]; k = self._scale_for(ycol, best_scale)\n",
    "                    Yt_full.append(y_tr[ycol].to_numpy(float) - (a + k*b*Xs_tr[scol].to_numpy(float)))\n",
    "                Yt_full = pd.DataFrame(np.column_stack(Yt_full), index=Xf_tr.index, columns=self.target_cols)\n",
    "\n",
    "                self._best_scale_ = best_scale\n",
    "                mlp = self._make_mlp_pipe(best_params or {})\n",
    "                mlp.fit(Xf_tr, Yt_full)\n",
    "                y_net_te = mlp.predict(x_te[self.feature_cols].to_frame().T)[0]\n",
    "            else:\n",
    "                # CV 없음: 고정 스케일 사용\n",
    "                Yt=[]\n",
    "                for ycol, scol in self.slope_map.items():\n",
    "                    a,b = ab[ycol]; k = self._scale_for(ycol, self.slope_scale)\n",
    "                    Yt.append(y_tr[ycol].to_numpy(float) - (a + k*b*Xs_tr[scol].to_numpy(float)))\n",
    "                Yt = pd.DataFrame(np.column_stack(Yt), index=Xf_tr.index, columns=self.target_cols)\n",
    "                mlp = self._make_mlp_pipe({})\n",
    "                mlp.fit(Xf_tr, Yt)\n",
    "                self._best_scale_ = self.slope_scale\n",
    "                y_net_te = mlp.predict(x_te[self.feature_cols].to_frame().T)[0]\n",
    "        else:\n",
    "            self._best_scale_ = self.slope_scale\n",
    "            y_net_te = np.zeros(len(self.target_cols), dtype=float)\n",
    "\n",
    "        # 테스트 시점의 slope 가지 출력\n",
    "        y_slope=[]\n",
    "        for ycol, scol in self.slope_map.items():\n",
    "            a,b = ab[ycol]; k = self._scale_for(ycol, self._best_scale_)\n",
    "            y_slope.append(a + k*b*float(x_te[scol]))\n",
    "        y_slope = np.array(y_slope, dtype=float)\n",
    "\n",
    "        y_hat = y_slope + y_net_te\n",
    "        return pd.Series(y_hat, index=self.target_cols)\n",
    "\n",
    "\n",
    "# ===================== RUN (two setups) =====================\n",
    "if __name__ == \"__main__\":\n",
    "    df = read_df(DATA_FILE)\n",
    "    y  = df[Y_COLS].copy()\n",
    "\n",
    "    # 특징세트\n",
    "    X_fwd       = make_features(df, use_slope=True, use_macro=False, use_fwd=True)\n",
    "    X_fwd_macro = make_features(df, use_slope=True, use_macro=True,  use_fwd=True)\n",
    "\n",
    "    slope_map = slope_map_from_targets(df, Y_COLS, SLOPE_PREFIX)\n",
    "\n",
    "    # ---- (1) Slope-skip + MLP on [fwd] ----\n",
    "    strat1 = SlopeSkipMLPStrategy(\n",
    "        target_cols=Y_COLS,\n",
    "        slope_map=slope_map,\n",
    "        feature_cols=[c for c in X_fwd.columns if not c.startswith(SLOPE_PREFIX)],\n",
    "        mlp_params=MLP_PARAMS,\n",
    "        mlp_cv=MLP_CV,                   # slope_scale 동시 탐색 포함\n",
    "        freeze_slope=FREEZE_SLOPE,\n",
    "        ema_rho=EMA_RHO,\n",
    "        slope_scale=FIXED_SLOPE_SCALE,   # MLP_CV에 slope_scale가 있으면 무시됨(그리드 우선)\n",
    "        scale_features=True,\n",
    "    )\n",
    "    runner1 = ExpandingRunner(X=X_fwd, y=y, strategy=strat1,\n",
    "                              period=PERIOD, burn_in_end=BURN_IN_END, horizon=HORIZON)\n",
    "    runner1.fit_walk(progress=SHOW_PROGRESS, desc=\"Slope-skip + MLP [fwd]\")\n",
    "\n",
    "    y_cs_hat_1 = cs_baseline(runner1.test_times, runner1.times, df, y, slope_map)\n",
    "    print(\"\\n=== Slope-skip + MLP [fwd] ===\")\n",
    "    print(\"R2OOS vs naive:\\n\",    runner1.R2OOS(baseline=\"naive\").round(4))\n",
    "    print(\"R2OOS vs condmean:\\n\", runner1.R2OOS(baseline=\"condmean\").round(4))\n",
    "    print(\"R2OOS vs CS OLS:\\n\",   runner1.R2OOS(baseline=\"custom\", benchmark=y_cs_hat_1).round(4))\n",
    "\n",
    "    if SAVE_MAT:\n",
    "        save_mat_with_components(MAT_PATH_1, runner1, y_cs_hat_1)\n",
    "\n",
    "    # ---- (2) Slope-skip + MLP on [fwd + macro] ----\n",
    "    strat2 = SlopeSkipMLPStrategy(\n",
    "        target_cols=Y_COLS,\n",
    "        slope_map=slope_map,\n",
    "        feature_cols=[c for c in X_fwd_macro.columns if not c.startswith(SLOPE_PREFIX)],\n",
    "        mlp_params=MLP_PARAMS,\n",
    "        mlp_cv=MLP_CV,\n",
    "        freeze_slope=FREEZE_SLOPE,\n",
    "        ema_rho=EMA_RHO,\n",
    "        slope_scale=FIXED_SLOPE_SCALE,\n",
    "        scale_features=True,\n",
    "    )\n",
    "    runner2 = ExpandingRunner(X=X_fwd_macro, y=y, strategy=strat2,\n",
    "                              period=PERIOD, burn_in_end=BURN_IN_END, horizon=HORIZON)\n",
    "    runner2.fit_walk(progress=SHOW_PROGRESS, desc=\"Slope-skip + MLP [fwd+macro]\")\n",
    "\n",
    "    y_cs_hat_2 = cs_baseline(runner2.test_times, runner2.times, df, y, slope_map)\n",
    "    print(\"\\n=== Slope-skip + MLP [fwd+macro] ===\")\n",
    "    print(\"R2OOS vs naive:\\n\",    runner2.R2OOS(baseline=\"naive\").round(4))\n",
    "    print(\"R2OOS vs condmean:\\n\", runner2.R2OOS(baseline=\"condmean\").round(4))\n",
    "    print(\"R2OOS vs CS OLS:\\n\",   runner2.R2OOS(baseline=\"custom\", benchmark=y_cs_hat_2).round(4))\n",
    "\n",
    "    if SAVE_MAT:\n",
    "        save_mat_with_components(MAT_PATH_2, runner2, y_cs_hat_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
